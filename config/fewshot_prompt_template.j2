<s>[INST]
You are an AI ethics researcher analyzing Reddit posts.
Your task is to classify whether the following post discusses **visual identity bias in AI-generated images**.

Definition of bias (focus of classification):
"Bias" refers specifically to unfair, distorted, or underrepresented visual portrayal of human identity in AI-generated images. Identity traits include:
- Race, gender, body type, disability, age, religion, culture, or socioeconomic status.

Label as "yes" if the post:
- Discusses how AI-generated images misrepresent or exclude identity traits.
- Mentions racial, gendered, cultural, or bodily stereotypes in image generation.
- Critiques underrepresentation or erasure of certain groups (e.g., “AI keeps making only thin white women”).
- Describes image tools failing to accurately depict diverse human appearances.

Label as "no" if the post:
- Discusses text-based AI (e.g., chatbots, Copilot writing bugs).
- Focuses on technical issues, creativity, or AI art ethics unrelated to identity.
- Talks about realism, aesthetics, or copyright without mentioning identity.
- Mentions censorship, politics, accessibility, or artist livelihoods without referencing identity representation in images.

Important:
- Only classify as "yes" if identity portrayal in AI images is a clear or implied topic.
- Ignore opinions on AI tools, automation, or artistic expression unless they explicitly relate to **visual identity bias**.

Examples:
Post: "When I ask Copilot to show 'mixed race' people, I get only white people unless I fix the spelling."
Label: yes  
Reasoning: The output defaults to white subjects when the identity term is misspelled, indicating racial underrepresentation and a biased fallback. 
This ties the generation error directly to visual identity portrayal (race), not mere image quality.

Post: "AI is making it harder for real artists to earn commissions."
Label: no  
Reasoning: This is about economic impact and labor markets, not about how AI images depict people. There is no reference to identity 
traits or representational patterns in the visuals.

Post: "My Asian friend tried generating a photo of herself in traditional clothes, but the AI gave her white features."
Label: yes  
Reasoning: The model produces mismatched racial features (white phenotype) 
for an Asian subject, showing misrepresentation/erasure of a 
non-white identity. The example explicitly concerns visual identity in AI images.

Post: "DALL·E refuses to generate images of war zones or protests due to content guidelines."
Label: no  
Reasoning: This describes content moderation/safety filtering, not biased depiction of demographic groups. No identity attribute 
is being stereotyped, omitted, or distorted in the images.

Post: "AI portraits look too glossy and fake, nothing like real oil paintings."
Label: no  
Reasoning: The complaint targets style/realism artifacts (aesthetic quality), not who is shown or how identities 
are represented. There’s no claim about race, gender, body type, or other identity traits in the visuals
in this example.

Now classify this post:

Post: "{{ post_text }}"

Your answer must strictly follow this format:
Label: yes or no
Reasoning: [Your reasoning in 1-2 sentences]
[/INST]
