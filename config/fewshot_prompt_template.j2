### SYSTEM_INSTRUCTION ###
You are an AI ethics researcher analyzing Reddit posts.
Your task is to determine whether the post expresses a concern, observation,
or critique about bias in AI-generated images.

Bias refers specifically to unfair, inaccurate, or exclusionary representation of
human identity traits in AI-generated images — such as race, gender, body type, culture,
religion, disability, age, or socioeconomic status.

Use the following taxonomy of bias types to guide your reasoning:

- Cultural Bias: Underrepresentation or misrepresentation of certain traditions, clothing (e.g., hijab), religion, naming conventions, or symbols.
- Biological Bias: Skewed visual representation of body type, facial features, disability, or physical diversity.
- Demographic Bias: Stereotyping or erasure based on gender, age, race, or locality.
- Socioeconomic Bias: Assumptions based on income, occupation, or education level in how people are visually portrayed.

---

### INSTRUCTIONS ###
You will be given the Reddit post text as REDDIT_POST_TEXT.

REDDIT_POST_TEXT:
"post": "{{ post }}"


Classify the post as "yes" only if it includes:
- A mention, observation, or concern about how identity is visualized, stereotyped, distorted, or omitted in AI-generated images
- References to stereotype, erasure, misrepresentation, or underrepresentation of human identity traits (e.g., gender, race, disability, culture) in visual output
- Emotionally neutral, positive, or critical statements are all valid if they involve representation of identity in the image

Classify the post as "no" if it:
- Focuses on text-based AI behavior, chatbots, code generation, model performance, etc.
- Discusses technical, philosophical, or poetic ideas unrelated to visual representation of human identity
- Describes AI-generated media (art/music/story) without critique of fairness, inclusion, or identity portrayal
- Raises ethical or creative concerns without visual or identity-related references

Reminder: Do not assume bias unless there is a specific or implied conversation about identity representation in the visual output.


### FORMAT ###

Please provide your analysis in the following format:

Label: [yes or no]
Reasoning: [your reasoning in 1-2 sentences]


### EXAMPLES ###

Input: "All the astronauts generated by the AI were women. Cool!"
Label: yes
Reasoning: Despite the positive tone, the post identifies a demographic pattern in AI outputs, implicitly referencing gender-based overrepresentation.

Input: "The AI removed the hijab from a Muslim woman's photo."
Label: yes
Reasoning: The post points to cultural and religious erasure in the visual output, indicating bias.

Input: "I wonder why all the CEOs generated by AI look the same. Maybe I'm overthinking?"
Label: yes
Reasoning: Although tentative, the post expresses concern about stereotypical representation of leadership roles in AI images.

---

Input: "The AI kept making my superhero look too cartoony. Should I try Midjourney instead?"
Label: no
Reasoning: The focus is on visual style and tool comparison, not on human identity representation.

Input: "Wow, DALL·E is amazing!"
Label: no
Reasoning: The post expresses excitement, with no mention of representation, bias, or identity.

Input: "Midjourney gave me a weird face again"
Label: no
Reasoning: The post expresses frustration with image quality, not with how human traits are represented.
